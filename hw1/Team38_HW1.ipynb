{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load HW1_Linear_Regression.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load HW1_Linear_Regression.py\n",
    "\n",
    "\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "###### Do not modify here ######\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add()\n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = graph_def\n",
    "    #strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "###### Do not modify  here ######\n",
    "\n",
    "###### Implement Data Preprocess here ######\n",
    "housing = fetch_california_housing()\n",
    "print(\"Shape of dataset:\", housing.data.shape)\n",
    "print(\"Shape of label:\", housing.target.shape)\n",
    "\n",
    "housing_data = housing.data\n",
    "housing_target = housing.target\n",
    "\n",
    "# normalize data\n",
    "\n",
    "#housing_data_tf = tf.constant(housing_data)\n",
    "#housing_data_mean = tf.reduce_mean(housing_data_tf, 0)\n",
    "#housing_data_mean_diff = tf.subtract(housing_data_tf, housing_data_mean)\n",
    "#housing_data_s = tf.reduce_sum(tf.square(housing_data_mean), 0)\n",
    "#housing_data_s = tf.sqrt(\n",
    "#                        tf.div(housing_data_s, (housing_data.shape[0] - 1)))\n",
    "#housing_data_t_statistic = tf.div(housing_data_mean_diff, housing_data_s)\n",
    "#housing_data = tf.Session().run(housing_data_t_statistic)\n",
    "#\n",
    "#np.set_printoptions(linewidth=200, edgeitems=10)\n",
    "##print(tf.Session().run(housing_data_mean_diff))\n",
    "##quit()\n",
    "\n",
    "# set training set count\n",
    "training_set_count = math.floor(housing.data.shape[0]*0.9)\n",
    "\n",
    "# add bias\n",
    "training_set_data = np.concatenate(\n",
    "        (housing_data[:training_set_count], np.ones((training_set_count, 1), dtype=np.int)),\n",
    "        axis=1\n",
    "        )\n",
    "\n",
    "testing_set_data = np.concatenate(\n",
    "        (housing_data[training_set_count:], np.ones((housing.data.shape[0] - training_set_count, 1), dtype=np.int)),\n",
    "        axis=1\n",
    "        )\n",
    "training_set_target = housing_target[:training_set_count]\n",
    "testing_set_target = housing_target[training_set_count:]\n",
    "\n",
    "print(\"Training set\")\n",
    "print(\"Shape of dataset:\", training_set_data.shape)\n",
    "print(\"Shape of label:\", training_set_target.shape)\n",
    "print(\"Testing set\")\n",
    "print(\"Shape of dataset:\", testing_set_data.shape)\n",
    "print(\"Shape of label:\", testing_set_target.shape)\n",
    "x_train = tf.constant(training_set_data)\n",
    "y_train = tf.constant(training_set_target, shape=[training_set_count,1])\n",
    "x_test = tf.constant(testing_set_data)\n",
    "y_test = tf.constant(testing_set_target, shape=[housing.data.shape[0] - training_set_count, 1])\n",
    "\n",
    "\n",
    "###### Implement Data Preprocess here ######\n",
    "\n",
    "###### Start TF session ######\n",
    "with tf.Session() as sess:\n",
    "    w = tf.matrix_inverse(tf.matmul(x_train, x_train, transpose_a=True))\n",
    "    w = tf.matmul(w, x_train, transpose_b=True)\n",
    "    w = tf.matmul(w, y_train)\n",
    "#    print(\"Weight:\", sess.run(w))\n",
    "###### Calculate error rate ######\n",
    "    y_hat = tf.matmul(x_test, w)\n",
    "    y_error_rate = tf.reduce_mean(tf.abs(tf.div(tf.subtract(y_hat, y_test), y_test)))\n",
    "    print(\"Error rate:\", sess.run(y_error_rate))\n",
    "###### Calculate error rate ######\n",
    "    show_graph(tf.get_default_graph().as_graph_def())\n",
    "###### Start TF session ######\n",
    "\n",
    "###### Graph ######\n",
    "\n",
    "# accroding to linear regression formula, we can compute weight using feature and label. (MatMul -> MatrixInverse -> MatMul[1-2])\n",
    "# after weight is comupted, we can apply weight to linear regression formula to get predicted result. (MatMul[3])\n",
    "# also, we using tensorflow API to compute error rate. (Sub -> div -> Abs -> Mean)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
